{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "train = pd.read_csv(\"/Users/mohan/NEU/Projects_and_Hackathon/stay-or-stray/train.csv\")\n",
    "test = pd.read_csv(\"/Users/mohan/NEU/Projects_and_Hackathon/stay-or-stray/test.csv\")\n",
    "\n",
    "log_train = pd.read_csv(\"/Users/mohan/NEU/Projects_and_Hackathon/stay-or-stray/log_train.csv\")\n",
    "log_test = pd.read_csv(\"/Users/mohan/NEU/Projects_and_Hackathon/stay-or-stray/log_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_train_df= log_train\n",
    "train_df = train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>time</th>\n",
       "      <th>source</th>\n",
       "      <th>event</th>\n",
       "      <th>object</th>\n",
       "      <th>hour</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>day</th>\n",
       "      <th>time_diff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>43980</td>\n",
       "      <td>2013-11-11 16:30:11</td>\n",
       "      <td>browser</td>\n",
       "      <td>page_close</td>\n",
       "      <td>3T6XwoiMKgol57cm29Rjy8FXVFcIomxl</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>49.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2648</td>\n",
       "      <td>2013-12-27 06:44:08</td>\n",
       "      <td>browser</td>\n",
       "      <td>access</td>\n",
       "      <td>UaqaZdJXEAHfzB9qbZkvAe2jc0xmI3Na</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>27</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>18588</td>\n",
       "      <td>2013-12-07 09:58:44</td>\n",
       "      <td>server</td>\n",
       "      <td>navigate</td>\n",
       "      <td>l0kj1vWrjGxi2YqQWGitPXDEoH5G5RYd</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2679</td>\n",
       "      <td>2014-01-05 13:51:34</td>\n",
       "      <td>browser</td>\n",
       "      <td>access</td>\n",
       "      <td>S64EUU2p7wiyAtSxjzfSS6jLaHB3Y9RJ</td>\n",
       "      <td>13</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2528</td>\n",
       "      <td>2013-12-17 12:09:36</td>\n",
       "      <td>server</td>\n",
       "      <td>access</td>\n",
       "      <td>DSPbj5O8mNBS0ccEiBGXnXJvTZstHNED</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>13.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      ID                time   source       event  \\\n",
       "0  43980 2013-11-11 16:30:11  browser  page_close   \n",
       "1   2648 2013-12-27 06:44:08  browser      access   \n",
       "2  18588 2013-12-07 09:58:44   server    navigate   \n",
       "3   2679 2014-01-05 13:51:34  browser      access   \n",
       "4   2528 2013-12-17 12:09:36   server      access   \n",
       "\n",
       "                             object  hour  day_of_week  day  time_diff  \n",
       "0  3T6XwoiMKgol57cm29Rjy8FXVFcIomxl    16            0   11       49.0  \n",
       "1  UaqaZdJXEAHfzB9qbZkvAe2jc0xmI3Na     6            4   27        2.0  \n",
       "2  l0kj1vWrjGxi2YqQWGitPXDEoH5G5RYd     9            5    7        1.0  \n",
       "3  S64EUU2p7wiyAtSxjzfSS6jLaHB3Y9RJ    13            6    5        1.0  \n",
       "4  DSPbj5O8mNBS0ccEiBGXnXJvTZstHNED    12            1   17       13.0  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'float' object has no attribute 'round'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[50], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m predtest\u001b[39m=\u001b[39m\u001b[39m0.51\u001b[39m\n\u001b[0;32m----> 2\u001b[0m predtest\u001b[39m.\u001b[39;49mround()\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'float' object has no attribute 'round'"
     ]
    }
   ],
   "source": [
    "predtest=0.51\n",
    "predtest.round()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pandas/core/reshape/merge.py:1203: RuntimeWarning: invalid value encountered in cast\n",
      "  if not (lk == lk.astype(rk.dtype))[~np.isnan(lk)].all():\n"
     ]
    }
   ],
   "source": [
    "log_train_df['time'] = pd.to_datetime(log_train_df['time'])\n",
    "\n",
    "# Extract features\n",
    "log_train_df['hour'] = log_train_df['time'].dt.hour\n",
    "log_train_df['day_of_week'] = log_train_df['time'].dt.dayofweek\n",
    "log_train_df['day'] = log_train_df['time'].dt.day\n",
    "\n",
    "# Count of events per ID\n",
    "event_count = log_train_df.groupby('ID')['event'].count().reset_index(name='event_count')\n",
    "\n",
    "# Count of unique sources per ID\n",
    "unique_sources = log_train_df.groupby('ID')['source'].nunique().reset_index(name='unique_sources')\n",
    "\n",
    "# Merge these features back to the original dataset on ID\n",
    "train_df_enriched = train_df.merge(event_count, on='ID', how='left')\n",
    "train_df_enriched = train_df_enriched.merge(unique_sources, on='ID', how='left')\n",
    "\n",
    "\n",
    "# Time difference features (e.g., average time between events for each ID)\n",
    "log_train_df['time_diff'] = log_train_df.sort_values(['ID', 'time']).groupby('ID')['time'].diff().dt.total_seconds()\n",
    "avg_time_diff = log_train_df.groupby('ID')['time_diff'].mean().reset_index(name='avg_time_diff')\n",
    "\n",
    "# Fill missing values for IDs that did not have event data\n",
    "\n",
    "\n",
    "train_df_enriched = train_df_enriched.merge(avg_time_diff, on='ID', how='left')\n",
    "\n",
    "# Fill missing values for IDs that did not have event data\n",
    "train_df_enriched.fillna({'event_count': 0, 'unique_sources': 0, \"avg_time_diff\":0}, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>X1</th>\n",
       "      <th>X2</th>\n",
       "      <th>X3</th>\n",
       "      <th>X4</th>\n",
       "      <th>X5</th>\n",
       "      <th>X6</th>\n",
       "      <th>X7</th>\n",
       "      <th>X8</th>\n",
       "      <th>X9</th>\n",
       "      <th>...</th>\n",
       "      <th>X134</th>\n",
       "      <th>X135</th>\n",
       "      <th>X136</th>\n",
       "      <th>X137</th>\n",
       "      <th>X138</th>\n",
       "      <th>X139</th>\n",
       "      <th>label</th>\n",
       "      <th>event_count</th>\n",
       "      <th>unique_sources</th>\n",
       "      <th>avg_time_diff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7054.0</td>\n",
       "      <td>2.015152</td>\n",
       "      <td>0.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>147131.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>132068.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>85195.0</td>\n",
       "      <td>2.071429</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>40.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1182.717949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>191948.0</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 144 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         ID        X1   X2    X3   X4   X5   X6   X7    X8   X9  ...  X134  \\\n",
       "0    7054.0  2.015152  0.0  32.0  NaN  4.0  NaN  NaN   7.0  6.0  ...   1.0   \n",
       "1  147131.0  1.000000  NaN   2.0  NaN  NaN  0.0  NaN   6.0  5.0  ...   3.0   \n",
       "2  132068.0  1.000000  NaN   1.0  NaN  2.0  NaN  0.0   9.0  1.0  ...   1.0   \n",
       "3   85195.0  2.071429  0.0   1.0  NaN  2.0  NaN  NaN   8.0  7.0  ...   2.0   \n",
       "4  191948.0  2.000000  NaN   2.0  0.0  2.0  NaN  NaN  14.0  2.0  ...   2.0   \n",
       "\n",
       "   X135  X136  X137  X138  X139  label  event_count  unique_sources  \\\n",
       "0   1.0   1.0   3.0   2.0   NaN      1          0.0             0.0   \n",
       "1   1.0   1.0   2.0  10.0   NaN      1          1.0             1.0   \n",
       "2   1.0   2.0   2.0   4.0   NaN      1          0.0             0.0   \n",
       "3   2.0   1.0   4.0   2.0   NaN      1         40.0             2.0   \n",
       "4   2.0   1.0   2.0   6.0   0.0      1          0.0             0.0   \n",
       "\n",
       "   avg_time_diff  \n",
       "0       0.000000  \n",
       "1       0.000000  \n",
       "2       0.000000  \n",
       "3    1182.717949  \n",
       "4       0.000000  \n",
       "\n",
       "[5 rows x 144 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df_enriched.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/lightgbm/callback.py:325: UserWarning: Early stopping is not available in dart mode\n",
      "  _log_warning('Early stopping is not available in dart mode')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1\n",
      "Fold 2\n",
      "Fold 3\n",
      "Fold 4\n",
      "Accuracy: 0.92\n",
      "[[61155  7086]\n",
      " [ 3780 63108]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.90      0.92     68241\n",
      "           1       0.90      0.94      0.92     66888\n",
      "\n",
      "    accuracy                           0.92    135129\n",
      "   macro avg       0.92      0.92      0.92    135129\n",
      "weighted avg       0.92      0.92      0.92    135129\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "from imblearn.over_sampling import ADASYN\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from lightgbm import early_stopping\n",
    "\n",
    "# Assuming 'train_df_enriched' is your dataset\n",
    "train_clean = train_df_enriched.dropna(subset=['label'])\n",
    "\n",
    "X = train_clean.drop(['label', 'ID'], axis=1)\n",
    "y = train_clean['label']\n",
    "\n",
    "# Initialize the SimpleImputer with 'median' strategy\n",
    "imputer = SimpleImputer(strategy='median')\n",
    "X_imputed = imputer.fit_transform(X)\n",
    "X_imputed_df = pd.DataFrame(X_imputed, columns=X.columns)\n",
    "\n",
    "# Resampling\n",
    "X_resampled, y_resampled = ADASYN().fit_resample(X_imputed_df, y)\n",
    "\n",
    "# Define improved model parameters\n",
    "params = {\n",
    "    'boosting_type': 'gbdt',\n",
    "    'objective': 'binary',\n",
    "    'metric': 'binary_logloss',\n",
    "    'learning_rate': 0.01,  # Lower learning rate\n",
    "    'num_leaves': 40,  # Slightly higher num_leaves\n",
    "    'max_depth': -1,\n",
    "    'min_child_samples': 30,  # Adjust to control over-fitting\n",
    "    'max_bin': 255,\n",
    "    'subsample': 0.8,  # Higher subsample\n",
    "    'subsample_freq': 1,\n",
    "    'colsample_bytree': 0.8,  # Higher colsample_bytree\n",
    "    'min_child_weight': 0.001,\n",
    "    'subsample_for_bin': 200000,\n",
    "    'min_split_gain': 0.0,\n",
    "    'reg_alpha': 0.1,  # L1 regularization\n",
    "    'reg_lambda': 0.1,  # L2 regularization\n",
    "    'verbose': -1\n",
    "}\n",
    "\n",
    "# Cross-validation and model training\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "predictions = np.zeros(len(X_resampled))\n",
    "feature_importance_df = pd.DataFrame()\n",
    "\n",
    "for fold_, (train_index, test_index) in enumerate(skf.split(X_resampled, y_resampled)):\n",
    "    print(f\"Fold {fold_}\")\n",
    "    X_train, X_valid = X_resampled.iloc[train_index], X_resampled.iloc[test_index]\n",
    "    y_train, y_valid = y_resampled.iloc[train_index], y_resampled.iloc[test_index]\n",
    "    \n",
    "    dtrain = lgb.Dataset(X_train, label=y_train)\n",
    "    dvalid = lgb.Dataset(X_valid, label=y_valid, reference=dtrain)\n",
    "    \n",
    "    # Train with early stopping\n",
    "    clf = lgb.train(params, dtrain, 1000, valid_sets=[dtrain, dvalid], callbacks=[early_stopping(stopping_rounds=100)])\n",
    "    \n",
    "    # Feature importance for later analysis\n",
    "    fold_importance_df = pd.DataFrame()\n",
    "    fold_importance_df[\"Feature\"] = X.columns\n",
    "    fold_importance_df[\"Importance\"] = clf.feature_importance(importance_type='gain')\n",
    "    fold_importance_df[\"Fold\"] = fold_ + 1\n",
    "    feature_importance_df = pd.concat([feature_importance_df, fold_importance_df], axis=0)\n",
    "    \n",
    "    predictions[test_index] = clf.predict(X_valid, num_iteration=clf.best_iteration)\n",
    "\n",
    "# Optional: Feature Selection based on importance\n",
    "# This step can be adjusted or iterated upon depending on results\n",
    "threshold = np.percentile(feature_importance_df[\"Importance\"], 75)  # Example threshold\n",
    "important_features = feature_importance_df[feature_importance_df[\"Importance\"] > threshold][\"Feature\"].unique()\n",
    "X_important_features = X_resampled[important_features]\n",
    "\n",
    "# You could repeat the model training here with X_important_features to see if performance improves\n",
    "\n",
    "# Final Model evaluation\n",
    "accuracy = accuracy_score(y_resampled, predictions.round())\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n",
    "print(confusion_matrix(y_resampled, predictions.round()))\n",
    "print(classification_report(y_resampled, predictions.round()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1_Score : 0.9207335755241388\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score,f1_score\n",
    "predicted_labels = np.round(predictions).astype(int)\n",
    "print('F1_Score :',f1_score(y_resampled,predicted_labels))\n",
    "#F1_Score : 0.9221600231637873 \n",
    "#F1_Score : 0.9229871645274212 - 0.1 median\n",
    "#F1_Score : 0.9242930498300427 - mean lightbgm\n",
    "#F1_Score : 0.9243412961382085 - median lightbgm\n",
    "#F1_Score : 0.9246502317282795 - lightbgm median learning rate= 0.01\n",
    "#F1_Score : 0.9207335755241388 - lightbgm median learning rate= 0.01 dart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC Score: 0.9198248761840062\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# true_labels = ... # This should be your array of true binary labels (0 or 1)\n",
    "# predicted_probs = ... # This should be your array of predicted probabilities for the positive class\n",
    "\n",
    "# Calculate AUC\n",
    "auc_score = roc_auc_score(y_resampled, predicted_labels)\n",
    "\n",
    "print(f'AUC Score: {auc_score}')\n",
    "#AUC Score: 0.9234141033971461 - lightbgm median learning rate= 0.01\n",
    "#AUC Score: 0.9198248761840062 - lightbgm median learning rate= 0.01 dart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/Users/mohan/NEU/Projects_and_Hackathon/stay-or-stray/Models/light_gbm_0.01LR.joblib']"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from joblib import dump\n",
    "\n",
    "# Assuming gbc is your GradientBoostingClassifier instance\n",
    "dump(clf, '/Users/mohan/NEU/Projects_and_Hackathon/stay-or-stray/Models/light_gbm_0.01LR.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from joblib import load\n",
    "\n",
    "#loaded_model = load('/content/drive/MyDrive/Hackathon_NEU/gbc_AD.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 0\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[220]\ttraining's binary_logloss: 0.167496\tvalid_1's binary_logloss: 0.20321\n",
      "Fold 1\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[203]\ttraining's binary_logloss: 0.170887\tvalid_1's binary_logloss: 0.205039\n",
      "Fold 2\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[239]\ttraining's binary_logloss: 0.165746\tvalid_1's binary_logloss: 0.202623\n",
      "Fold 3\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[205]\ttraining's binary_logloss: 0.17047\tvalid_1's binary_logloss: 0.20303\n",
      "Fold 4\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[233]\ttraining's binary_logloss: 0.165603\tvalid_1's binary_logloss: 0.203537\n",
      "Accuracy: 0.92\n",
      "[[60787  7454]\n",
      " [ 3004 63884]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.89      0.92     68241\n",
      "           1       0.90      0.96      0.92     66888\n",
      "\n",
      "    accuracy                           0.92    135129\n",
      "   macro avg       0.92      0.92      0.92    135129\n",
      "weighted avg       0.92      0.92      0.92    135129\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "from imblearn.over_sampling import ADASYN\n",
    "from lightgbm import early_stopping\n",
    "\n",
    "\n",
    "# Assuming 'train_df_enriched' is your dataset\n",
    "train_clean = train_df_enriched.dropna(subset=['label'])\n",
    "\n",
    "X = train_clean.drop(['label', 'ID'], axis=1)\n",
    "y = train_clean['label']\n",
    "\n",
    "# Initialize the SimpleImputer with 'mean' strategy\n",
    "imputer = SimpleImputer(strategy='median')\n",
    "X_imputed = imputer.fit_transform(X)\n",
    "X_imputed_df = pd.DataFrame(X_imputed, columns=X.columns)\n",
    "\n",
    "# Resampling\n",
    "X_resampled, y_resampled = ADASYN().fit_resample(X_imputed_df, y)\n",
    "\n",
    "# Define model parameters (customize as needed)\n",
    "params = {\n",
    "    'boosting_type': 'gbdt',\n",
    "    'objective': 'binary',\n",
    "    'metric': 'binary_logloss',\n",
    "    'learning_rate': 0.1,\n",
    "    'num_leaves': 31,\n",
    "    'max_depth': -1,\n",
    "    'min_child_samples': 20,\n",
    "    'max_bin': 255,\n",
    "    'subsample': 0.6,\n",
    "    'subsample_freq': 0,\n",
    "    'colsample_bytree': 0.3,\n",
    "    'min_child_weight': 5,\n",
    "    'subsample_for_bin': 200000,\n",
    "    'min_split_gain': 0,\n",
    "    'reg_alpha': 0,\n",
    "    'reg_lambda': 0,\n",
    "    'verbose': 0\n",
    "}\n",
    "\n",
    "# Cross-validation and model training\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "predictions = np.zeros(len(X_resampled))\n",
    "feature_importance_df = pd.DataFrame()\n",
    "\n",
    "for fold_, (train_index, test_index) in enumerate(skf.split(X_resampled, y_resampled)):\n",
    "    print(f\"Fold {fold_}\")\n",
    "    X_train, X_valid = X_resampled.iloc[train_index], X_resampled.iloc[test_index]\n",
    "    y_train, y_valid = y_resampled.iloc[train_index], y_resampled.iloc[test_index]\n",
    "    \n",
    "    dtrain = lgb.Dataset(X_train, label=y_train)\n",
    "    dvalid = lgb.Dataset(X_valid, label=y_valid, reference=dtrain)\n",
    "    \n",
    "    clf = lgb.train(params, dtrain, 10000, valid_sets=[dtrain, dvalid],callbacks=[early_stopping(stopping_rounds=100)])\n",
    "    \n",
    "    # Feature importance\n",
    "    fold_importance_df = pd.DataFrame()\n",
    "    fold_importance_df[\"Feature\"] = X.columns\n",
    "    fold_importance_df[\"Importance\"] = clf.feature_importance()\n",
    "    fold_importance_df[\"Fold\"] = fold_ + 1\n",
    "    feature_importance_df = pd.concat([feature_importance_df, fold_importance_df], axis=0)\n",
    "    \n",
    "    predictions[test_index] = clf.predict(X_valid, num_iteration=clf.best_iteration)\n",
    "\n",
    "# Model evaluation\n",
    "accuracy = accuracy_score(y_resampled, predictions.round())\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n",
    "print(confusion_matrix(y_resampled, predictions.round()))\n",
    "print(classification_report(y_resampled, predictions.round()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1_Score : 0.9243412961382085\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score,f1_score\n",
    "predicted_labels = np.round(predictions)\n",
    "print('F1_Score :',f1_score(y_resampled,predicted_labels))\n",
    "#F1_Score : 0.9221600231637873 \n",
    "#F1_Score : 0.9229871645274212 - 0.1 median\n",
    "#F1_Score : 0.9242930498300427 - mean lightbgm\n",
    "#F1_Score : 0.9243412961382085 - median lightbgm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_test_df=log_test\n",
    "test_df = test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_test_df['time'] = pd.to_datetime(log_test_df['time'])\n",
    "\n",
    "# Extract features\n",
    "log_test_df['hour'] = log_test_df['time'].dt.hour\n",
    "log_test_df['day_of_week'] = log_test_df['time'].dt.dayofweek\n",
    "log_test_df['day'] = log_test_df['time'].dt.day\n",
    "\n",
    "# Count of events per ID\n",
    "event_count = log_test_df.groupby('ID')['event'].count().reset_index(name='event_count')\n",
    "\n",
    "# Count of unique sources per ID\n",
    "unique_sources = log_test_df.groupby('ID')['source'].nunique().reset_index(name='unique_sources')\n",
    "\n",
    "# Merge these features back to the original dataset on ID\n",
    "test_df_enriched = test_df.merge(event_count, on='ID', how='left')\n",
    "test_df_enriched = test_df_enriched.merge(unique_sources, on='ID', how='left')\n",
    "\n",
    "\n",
    "\n",
    "# Time difference features (e.g., average time between events for each ID)\n",
    "log_test_df['time_diff'] = log_test_df.sort_values(['ID', 'time']).groupby('ID')['time'].diff().dt.total_seconds()\n",
    "avg_time_diff = log_test_df.groupby('ID')['time_diff'].mean().reset_index(name='avg_time_diff')\n",
    "\n",
    "\n",
    "\n",
    "test_df_enriched = test_df_enriched.merge(avg_time_diff, on='ID', how='left')\n",
    "\n",
    "# Fill missing values for IDs that did not have event data\n",
    "test_df_enriched.fillna({'event_count': 0, 'unique_sources': 0, 'avg_time_diff':0}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>X1</th>\n",
       "      <th>X2</th>\n",
       "      <th>X3</th>\n",
       "      <th>X4</th>\n",
       "      <th>X5</th>\n",
       "      <th>X6</th>\n",
       "      <th>X7</th>\n",
       "      <th>X8</th>\n",
       "      <th>X9</th>\n",
       "      <th>...</th>\n",
       "      <th>X133</th>\n",
       "      <th>X134</th>\n",
       "      <th>X135</th>\n",
       "      <th>X136</th>\n",
       "      <th>X137</th>\n",
       "      <th>X138</th>\n",
       "      <th>X139</th>\n",
       "      <th>event_count</th>\n",
       "      <th>unique_sources</th>\n",
       "      <th>avg_time_diff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17547.0</td>\n",
       "      <td>1.272727</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>124.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>140449.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>37.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>182658.0</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>155.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>149652.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>95.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>106304.0</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 143 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         ID        X1   X2   X3   X4   X5   X6   X7    X8    X9  ...  X133  \\\n",
       "0   17547.0  1.272727  0.0  1.0  0.0  3.0  0.0  0.0   7.0  26.0  ...   0.0   \n",
       "1  140449.0  1.000000  0.0  1.0  NaN  1.0  NaN  0.0   8.0   4.0  ...   0.0   \n",
       "2  182658.0  2.000000  NaN  2.0  NaN  2.0  NaN  0.0  64.0   2.0  ...   NaN   \n",
       "3  149652.0  1.000000  0.0  1.0  NaN  1.0  0.0  0.0   9.0   9.0  ...   NaN   \n",
       "4  106304.0  2.000000  NaN  2.0  NaN  3.0  NaN  0.0   1.0   6.0  ...   0.0   \n",
       "\n",
       "   X134  X135  X136  X137  X138  X139  event_count  unique_sources  \\\n",
       "0   2.0   6.0   2.0   4.0   3.0   NaN          2.0             2.0   \n",
       "1   3.0   2.0   2.0   2.0   5.0   NaN          4.0             1.0   \n",
       "2   2.0   4.0   1.0   1.0   7.0   0.0          2.0             2.0   \n",
       "3   3.0   1.0   1.0   2.0   7.0   NaN          5.0             1.0   \n",
       "4   1.0   2.0   2.0   2.0   2.0   0.0          0.0             0.0   \n",
       "\n",
       "   avg_time_diff  \n",
       "0         124.00  \n",
       "1          37.00  \n",
       "2         155.00  \n",
       "3          95.25  \n",
       "4           0.00  \n",
       "\n",
       "[5 rows x 143 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df_enriched.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       ID  LABEL\n",
      "0   17547      0\n",
      "1  140449      1\n",
      "2  182658      1\n",
      "3  149652      1\n",
      "4  106304      1\n"
     ]
    }
   ],
   "source": [
    "# Assuming `test_df_enriched` is your test dataset and `clf` is your trained LightGBM model\n",
    "\n",
    "# Convert the 'ID' column from float to int\n",
    "test_df_enriched['ID'] = test_df_enriched['ID'].astype(int)\n",
    "\n",
    "# Separate out the 'ID' column and features from the 'test' dataset\n",
    "test_features = test_df_enriched.drop('ID', axis=1)\n",
    "\n",
    "# Impute the 'test' dataset using the fitted SimpleImputer\n",
    "# Note: We use .transform() here, NOT .fit_transform()\n",
    "test_imputed = imputer.transform(test_features)\n",
    "\n",
    "# Predict the labels using the trained LightGBM model\n",
    "predicted_labels = clf.predict(test_imputed)\n",
    "\n",
    "# For binary classification, LightGBM might output probabilities. If so, convert these to 0 or 1\n",
    "# Uncomment the following line if your model outputs probabilities\n",
    "predicted_labels = np.round(predicted_labels).astype(int)\n",
    "\n",
    "# Create a DataFrame with 'ID' and the predicted 'label'\n",
    "results_df = pd.DataFrame({\n",
    "    'ID': test_df_enriched['ID'],\n",
    "    'LABEL': predicted_labels\n",
    "})\n",
    "\n",
    "# Optionally, convert the 'LABEL' column to the desired format, e.g., int\n",
    "# results_df['LABEL'] = results_df['LABEL'].astype(int)\n",
    "\n",
    "# Output the DataFrame with 'ID' and 'label'\n",
    "# Save to a CSV file\n",
    "results_df.to_csv('/Users/mohan/NEU/Projects_and_Hackathon/stay-or-stray/Submissions/my_submission_22_lightGBM_ADASYN_mdn_0.01LR.csv', index=False)\n",
    "\n",
    "# Display the first few rows of the DataFrame\n",
    "print(results_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
